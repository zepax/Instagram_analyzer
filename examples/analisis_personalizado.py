#!/usr/bin/env python3
"""AnÃ¡lisis personalizado de Instagram con reporte HTML optimizado."""

from datetime import datetime, timedelta
from pathlib import Path

from instagram_analyzer.core.analyzer import InstagramAnalyzer
from instagram_analyzer.exporters import HTMLExporter
from instagram_analyzer.extractors.conversation_extractor import (
    ConversationExtractor,
    extract_conversations_with_keywords,
)
from instagram_analyzer.models.conversation import Conversation, ConversationAnalysis


def generar_analisis_completo() -> Path:
    """Genera un anÃ¡lisis completo con reporte HTML optimizado."""

    print("ğŸš€ Iniciando anÃ¡lisis completo de Instagram...")

    # ============ CONFIGURACIÃ“N ============

    # 1. DATASET - Cambiar esta ruta por la tuya
    mi_dataset = Path("data/sample_exports")

    # 2. CONFIGURACIÃ“N DEL REPORTE
    output_path = Path("mi_analisis_personalizado")
    output_path.mkdir(exist_ok=True)

    anonymize = False  # Cambiar a True si quieres anonimizar datos
    embed_images = True  # True para ver imÃ¡genes (recomendado)

    # ============ ANÃLISIS PRINCIPAL ============

    print("ğŸ“Š Cargando datos de Instagram...")
    analyzer = InstagramAnalyzer(mi_dataset)
    analyzer.load_data()

    # Mostrar estadÃ­sticas
    print("âœ… Datos cargados:")
    print(f"   ğŸ“± Posts: {len(analyzer.posts)}")
    print(f"   ğŸ“– Stories: {len(analyzer.stories)}")
    print(f"   ğŸ¬ Reels: {len(analyzer.reels)}")

    # Generar reporte HTML
    print("ğŸ¨ Generando reporte HTML...")
    html_exporter = HTMLExporter()
    html_path = html_exporter.export(
        analyzer=analyzer,
        output_path=output_path,
        anonymize=anonymize,
        # embed_images parameter removed - no longer supported
    )

    print(f"âœ¨ Reporte HTML generado en: {html_path}")
    return html_path


def analizar_mis_conversaciones() -> tuple[list[Conversation], ConversationAnalysis]:
    """Ejecuta anÃ¡lisis de conversaciones (opcional)."""

    # ============ CONFIGURACIÃ“N DE CONVERSACIONES ============

    # 1. TU DATASET - Cambiar esta ruta por la tuya
    mi_dataset = Path("data/sample_exports/instagram-pcFuHXmB/")

    # 2. TUS PALABRAS CLAVE - Personaliza segÃºn tus intereses
    # Cargar palabras clave desde archivo
    keywords_file = Path("keywords.txt")  # Cambiar por la ruta a tu archivo
    if keywords_file.exists():
        with open(keywords_file, encoding="utf-8") as f:
            mis_palabras_clave = [line.strip() for line in f if line.strip()]
        print(
            f"âœ… Cargadas {len(mis_palabras_clave)} palabras clave desde {keywords_file}"
        )
    else:
        print(f"âŒ No se encontrÃ³ el archivo {keywords_file}")
        print("ğŸ“ Creando archivo de ejemplo...")
        # Crear archivo de ejemplo con algunas palabras
        with open(keywords_file, "w", encoding="utf-8") as f:
            f.write("amor\ncariÃ±o\ngracias\nhola\n")
        mis_palabras_clave = ["amor", "cariÃ±o", "gracias", "hola"]
        print(f"âœ… Archivo {keywords_file} creado con palabras de ejemplo")

    # 3. TUS FILTROS PERSONALIZADOS
    filtros_personalizados = {
        "min_messages": 5,  # Solo conversaciones activas (reducido)
        "exclude_empty": True,  # Sin conversaciones vacÃ­as
        # 'max_messages': 500,     # Opcional: limitar conversaciones largas
    }

    # 4. RANGO DE FECHAS (opcional)
    meses_atras = 140  # Analizar Ãºltimos 12 meses
    fecha_fin = datetime.now()
    fecha_inicio = fecha_fin - timedelta(days=30 * meses_atras)

    # ============ EJECUCIÃ“N DEL ANÃLISIS ============

    print("ğŸ” Iniciando anÃ¡lisis personalizado de conversaciones")
    print(f"ğŸ“ Dataset: {mi_dataset}")
    print(f"ğŸ”¤ Palabras clave: {', '.join(mis_palabras_clave)}")
    print(
        f"ğŸ“… PerÃ­odo: {fecha_inicio.strftime('%Y-%m-%d')} a "
        f"{fecha_fin.strftime('%Y-%m-%d')}"
    )

    # Inicializar extractor
    extractor = ConversationExtractor(mi_dataset, max_workers=4)
    extractor.set_filters(**filtros_personalizados)

    # ANÃLISIS 1: Conversaciones con palabras clave
    print("\nğŸ¯ Buscando conversaciones con palabras clave...")
    conversaciones_palabras = extract_conversations_with_keywords(
        mi_dataset, mis_palabras_clave
    )

    print(
        f"âœ… Encontradas {len(conversaciones_palabras)} "
        "conversaciones con tus palabras"
    )

    # Mostrar top 10 mÃ¡s activas
    conversaciones_ordenadas = sorted(
        conversaciones_palabras, key=lambda c: len(c.messages), reverse=True
    )

    print("\nğŸ”¥ Top 10 conversaciones mÃ¡s activas con tus palabras:")
    for i, conv in enumerate(conversaciones_ordenadas[:10], 1):
        # Buscar cuÃ¡les palabras se encontraron
        palabras_encontradas = []
        for palabra in mis_palabras_clave:
            if any(
                msg.content and palabra.lower() in msg.content.lower()
                for msg in conv.messages
                if msg.content
            ):
                palabras_encontradas.append(palabra)

        print(f"   {i}. {conv.title[:35]}... ({len(conv.messages)} msgs)")
        print(f"      Palabras: {', '.join(palabras_encontradas[:5])}")

    # ANÃLISIS 2: Conversaciones por perÃ­odo de tiempo
    print(
        f"\nğŸ“… Analizando conversaciones del perÃ­odo "
        f"{fecha_inicio.strftime('%Y-%m-%d')} al "
        f"{fecha_fin.strftime('%Y-%m-%d')}..."
    )

    conversaciones_periodo = extractor.extract_conversations_by_criteria(
        date_range=(fecha_inicio, fecha_fin),
        min_message_count=filtros_personalizados["min_messages"],
    )

    print(
        f"âœ… Encontradas {len(conversaciones_periodo)} conversaciones "
        "activas en el perÃ­odo"
    )

    # ANÃLISIS 3: AnÃ¡lisis completo y exportaciÃ³n
    print("\nğŸ§  Ejecutando anÃ¡lisis completo...")

    output_dir = Path("mi_analisis_personalizado/analisis_completo")
    conversaciones_completas, analisis_completo = extractor.extract_and_analyze(
        export_path=output_dir,
        include_advanced_analytics=True,
        anonymize=False,  # Cambia a True si quieres anonimizar
    )

    print("âœ… AnÃ¡lisis completo terminado:")
    print(f"   â€¢ Total conversaciones: {len(conversaciones_completas)}")
    print(f"   â€¢ Total mensajes: {analisis_completo.total_messages}")
    print(f"   â€¢ Contactos Ãºnicos: {analisis_completo.unique_contacts}")

    # ANÃLISIS 4: EstadÃ­sticas personalizadas
    print("\nğŸ“Š EstadÃ­sticas de tu anÃ¡lisis:")
    # AnÃ¡lisis de palabras mÃ¡s frecuentes
    contador_palabras: dict[str, int] = {}
    # Este bucle itera sobre las conversaciones que ya tienen el anÃ¡lisis de frecuencia de palabras clave.
    # El anÃ¡lisis se realiza dentro de `extractor.extract_and_analyze` si `include_advanced_analytics=True`.
    for conv in conversaciones_completas:
        if hasattr(conv, "keyword_frequency") and conv.keyword_frequency:
            for palabra, freq in conv.keyword_frequency.items():
                if palabra.lower() in [p.lower() for p in mis_palabras_clave]:
                    contador_palabras[palabra] = contador_palabras.get(palabra, 0) + freq

    if contador_palabras:
        print("   Frecuencia de tus palabras clave:")
        palabras_ordenadas = sorted(
            contador_palabras.items(), key=lambda x: x[1], reverse=True
        )
        for palabra, freq in palabras_ordenadas[:10]:
            print(f"      â€¢ {palabra}: {freq} veces")

    # Conversaciones mÃ¡s largas
    conv_largas = sorted(
        conversaciones_completas, key=lambda c: len(c.messages), reverse=True
    )[:5]
    print("   Top 5 conversaciones mÃ¡s largas:")
    for i, conv in enumerate(conv_largas, 1):
        print(f"      {i}. {conv.title[:30]}... - {len(conv.messages)} " "mensajes")

    print(f"\nğŸ’¾ Resultados guardados en: {output_dir}")
    print("   â€¢ conversation_extraction_results.json - AnÃ¡lisis completo")
    print("   â€¢ conversations/ - Detalles de conversaciones individuales")

    return conversaciones_completas, analisis_completo


def ejemplo_busqueda_rapida() -> None:
    """Ejemplo de bÃºsqueda rÃ¡pida por palabras clave."""

    print("\n" + "=" * 50)
    print("ğŸš€ EJEMPLO DE BÃšSQUEDA RÃPIDA")
    print("=" * 50)

    # ConfiguraciÃ³n rÃ¡pida
    dataset = Path("data/sample_exports/instagram-pcFuHXmB")
    palabras_buscar = ["gracias", "hola", "jaja"]

    print(f"Buscando: {', '.join(palabras_buscar)}")

    # BÃºsqueda rÃ¡pida
    busqueda_rapida_conversaciones = extract_conversations_with_keywords(
        dataset, palabras_buscar
    )

    print(f"âœ… Encontradas {len(busqueda_rapida_conversaciones)} conversaciones")

    for i, conv in enumerate(busqueda_rapida_conversaciones[:5], 1):
        print(f"   {i}. {conv.title[:40]}... ({len(conv.messages)} mensajes)")


def ejemplo_filtros_avanzados() -> None:
    """Ejemplo con filtros avanzados."""

    print("\n" + "=" * 50)
    print("ğŸ¯ EJEMPLO DE FILTROS AVANZADOS")
    print("=" * 50)

    dataset = Path("data/sample_exports/instagram-pcFuHXmB")
    extractor = ConversationExtractor(dataset)

    # Configurar filtros especÃ­ficos
    extractor.set_filters(
        min_messages=50,  # Solo conversaciones con 10+ mensajes
    )

    # Extraer con filtros
    conversaciones_filtradas = extractor.extract_all_conversations()
    print(f"âœ… Conversaciones filtradas: {len(conversaciones_filtradas)}")

    # EstadÃ­sticas
    stats = extractor.get_extraction_statistics()
    print(f"ğŸ“Š Tasa de Ã©xito: {stats.get('success_rate', 0):.1f}%")
    velocidad = stats.get("processing_rate_conversations_per_second", 0)
    print(f"âš¡ Velocidad: {velocidad:.1f} conv/seg")


if __name__ == "__main__":
    try:
        print("ğŸ” ANÃLISIS PERSONALIZADO DE CONVERSACIONES")
        print("=" * 60)

        # Ejecutar anÃ¡lisis completo
        conversaciones_resultado, analisis_resultado = analizar_mis_conversaciones()

        # Ejecutar ejemplos adicionales
        # ejemplo_busqueda_rapida()
        ejemplo_filtros_avanzados()

        print("\n" + "=" * 60)
        print("âœ… TODOS LOS ANÃLISIS COMPLETADOS EXITOSAMENTE")
        print("=" * 60)

        print("\nğŸ’¡ Para personalizar tu anÃ¡lisis:")
        print("   1. Cambia mi_dataset por la ruta a tu dataset")
        print("   2. Modifica mis_palabras_clave con tus palabras de interÃ©s")
        print("   3. Ajusta filtros_personalizados segÃºn tus necesidades")
        print("   4. Ejecuta: python examples/analisis_personalizado.py")

    except (FileNotFoundError, ValueError) as e:
        print(f"\nâŒ Error de configuraciÃ³n o datos: {e}")
        print("   AsegÃºrate de que la ruta a 'mi_dataset' es correcta.")
    except Exception as e:
        print(f"\nâŒ OcurriÃ³ un error inesperado durante el anÃ¡lisis: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    # Genera anÃ¡lisis completo por defecto
    print("ğŸ¯ Generando anÃ¡lisis completo de Instagram...")
    try:
        html_path = generar_analisis_completo()
        print(f"\nğŸ‰ Â¡AnÃ¡lisis completado!")
        print(f"ğŸ“„ Abre el archivo: {html_path}")
        print(f"ğŸ”— URL: file://{html_path.absolute()}")

        # Opcional: tambiÃ©n ejecutar anÃ¡lisis de conversaciones
        respuesta = input("\nâ“ Â¿TambiÃ©n quieres analizar conversaciones? (y/N): ")
        if respuesta.lower() in ["y", "yes", "sÃ­", "si"]:
            print("\nğŸ“± Ejecutando anÃ¡lisis de conversaciones...")
            analizar_mis_conversaciones()

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
